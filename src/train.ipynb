{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":176,"status":"ok","timestamp":1658442497393,"user":{"displayName":"Charles C","userId":"07085794940081015663"},"user_tz":420},"id":"cmsGhOs4vAuA","outputId":"6cf510b2-a7d4-4ff3-87fd-94144fbe8756"},"outputs":[{"name":"stdout","output_type":"stream","text":["Thu Jul 21 22:28:17 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":10383,"status":"ok","timestamp":1658442507980,"user":{"displayName":"Charles C","userId":"07085794940081015663"},"user_tz":420},"id":"alLOMYe2UgeF"},"outputs":[],"source":["!pip install datasets -q\n","!pip install transformers -q -U\n","!pip install wandb -q -U"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":525,"status":"ok","timestamp":1658442508503,"user":{"displayName":"Charles C","userId":"07085794940081015663"},"user_tz":420},"id":"3Zeo0Kk5WV9L"},"outputs":[],"source":["import pandas as pd\n","import datasets\n","import sys, importlib\n","import random\n","import shutil"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2000,"status":"ok","timestamp":1658442510502,"user":{"displayName":"Charles C","userId":"07085794940081015663"},"user_tz":420},"id":"IZItXZ1SMjK1","outputId":"e8b51f7e-ef09-4986-b88c-be3e8828fdb7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["import os\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive')\n","DS_HOME = '/content/gdrive/Shareddrives/cs224n-final-project/injury-icd-dataset'\n","CODE_HOME = '/content/gdrive/Shareddrives/cs224n-final-project/code'\n","# CODE_HOME_PRETRAIN = '/content/gdrive/Shareddrives/cs224n-final-project/pretrain/code'\n","# MODEL_HOME_PRETRAIN = '/content/gdrive/Shareddrives/cs224n-final-project/pretrain/models'\n","TMP_DIR = '/content/tmp'\n","\n","if not os.path.exists(TMP_DIR):\n","    os.mkdir(TMP_DIR)\n","\n","os.chdir(CODE_HOME)\n","# os.chdir(CODE_HOME_PRETRAIN)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["EXPERIMENT_NAME = \"non-sup-pretrain\"\n","NUM_EPOCHS = 20\n","IS_PRETRAIN = False  # Whether to just pretrain on 5-char codes\n","IS_EVALUATE = False  # Whether to just evaluate and not train"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1658442510502,"user":{"displayName":"Charles C","userId":"07085794940081015663"},"user_tz":420},"id":"H4ASD5mMREhq"},"outputs":[],"source":["# !rm -rf /content/gdrive/Shareddrives/cs224n-final-project/pretrain/models/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext/encoded_ds"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ptIEdaI6Wg9_","outputId":"bbe3682e-7cf5-4c10-eed7-8601ce7deba7"},"outputs":[{"name":"stdout","output_type":"stream","text":["07/21/2022 22:28:34 - INFO - dataset - Not in pretrain mode, so loading 4-character ICD-10 labels and dataset...\n","07/21/2022 22:28:35 - INFO - dataset - 15762 cases are read from /content/gdrive/Shareddrives/cs224n-final-project/injury-icd-dataset/case-labels.csv\n","07/21/2022 22:28:35 - INFO - dataset - 170 valid labels are read from /content/gdrive/Shareddrives/cs224n-final-project/injury-icd-dataset/label-non-superficial.txt\n","07/21/2022 22:28:36 - INFO - __main__ - Loading base model and tokenizer: michiyasunaga/BioLinkBERT-base...\n","07/21/2022 22:28:38 - INFO - model - Found pre-trained model config file at model_dir/model_name, so loading model checkpoint from /content/gdrive/Shareddrives/cs224n-final-project/pretrain/models/michiyasunaga/BioLinkBERT-base...\n","07/21/2022 22:28:45 - INFO - __main__ - Loading existing tokenized dataset...\n","07/21/2022 22:29:08 - INFO - __main__ - Loaded tokenized dataset from /content/gdrive/Shareddrives/cs224n-final-project/pretrain/models/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/encoded_ds\n","07/21/2022 22:29:15 - INFO - __main__ - Training...\n","The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: icd_code, icd_name, patient_id, context. If icd_code, icd_name, patient_id, context are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","07/21/2022 22:29:16 - INFO - __main__ - There are 9182 positive and 397798 negative examples in training set.\n","07/21/2022 22:29:16 - INFO - __main__ - Using weighted sampling: positive weight = 1.00 , negative weight = 0.02\n","07/21/2022 22:29:16 - INFO - __main__ - We will draw 18364 context-label pairs during one epoch.\n","***** Running training *****\n","  Num examples = 406980\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 22960\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: icd_code, icd_name, patient_id, context. If icd_code, icd_name, patient_id, context are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","07/21/2022 22:45:27 - INFO - __main__ - Performing evaluation...\n","***** Running Evaluation *****\n","  Num examples = 17340\n","  Batch size = 32\n","{'eval_loss': 0.3084690570831299, 'eval_threshold': 0.16, 'eval_accuracy': 0.02524271844660194, 'eval_f1_score_micro': 0.5702908587257618, 'eval_f1_score_macro': 0.44092330880046204, 'eval_f1_score_samples': 0.5559277980842159, 'eval_f1_score_weighted': 0.6305987986987192, 'eval_auc_score_micro': 0.9824833739222415, 'eval_auc_score_macro': 0.9736117331395593, 'eval_auc_score_samples': 0.9833529617421297, 'eval_auc_score_weighted': 0.9694455064199058, 'eval_targets_shape': (515, 170), 'eval_probs_shape': (515, 170), 'eval_precision@1': 0.8097087378640777, 'eval_precision@5': 0.45514563106796124, 'eval_precision@8': 0.354126213592233, 'eval_precision@10': 0.30699029126213595, 'eval_precision@15': 0.22951456310679613, 'eval_precision@20': 0.18155339805825244, 'eval_recall@1': 0.34787797324460584, 'eval_recall@5': 0.7195679954520017, 'eval_recall@8': 0.827567051128625, 'eval_recall@10': 0.8682930221995117, 'eval_recall@15': 0.9314163649613318, 'eval_recall@20': 0.9598382603032577, 'epoch': 1.0}\n","Saving model checkpoint to /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-1148\n","Configuration saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-1148/config.json\n","Model weights saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-1148/pytorch_model.bin\n","tokenizer config file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-1148/tokenizer_config.json\n","Special tokens file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-1148/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: icd_code, icd_name, patient_id, context. If icd_code, icd_name, patient_id, context are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","07/21/2022 23:06:04 - INFO - __main__ - Performing evaluation...\n","***** Running Evaluation *****\n","  Num examples = 17340\n","  Batch size = 32\n","{'eval_loss': 0.3480754792690277, 'eval_threshold': 0.41, 'eval_accuracy': 0.04660194174757282, 'eval_f1_score_micro': 0.6225114854517612, 'eval_f1_score_macro': 0.4621951496414156, 'eval_f1_score_samples': 0.6039000924107469, 'eval_f1_score_weighted': 0.6596942453432391, 'eval_auc_score_micro': 0.9854782757093833, 'eval_auc_score_macro': 0.9767442491102212, 'eval_auc_score_samples': 0.986614515122138, 'eval_auc_score_weighted': 0.9738563194305193, 'eval_targets_shape': (515, 170), 'eval_probs_shape': (515, 170), 'eval_precision@1': 0.8485436893203884, 'eval_precision@5': 0.4881553398058253, 'eval_precision@8': 0.3711165048543689, 'eval_precision@10': 0.31980582524271844, 'eval_precision@15': 0.2341747572815534, 'eval_precision@20': 0.18436893203883495, 'eval_recall@1': 0.3695061131737166, 'eval_recall@5': 0.7543809646607296, 'eval_recall@8': 0.8535691568126418, 'eval_recall@10': 0.8918043897566125, 'eval_recall@15': 0.9446505562512205, 'eval_recall@20': 0.9726355853310377, 'epoch': 2.0}\n","Saving model checkpoint to /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-2296\n","Configuration saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-2296/config.json\n","Model weights saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-2296/pytorch_model.bin\n","tokenizer config file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-2296/tokenizer_config.json\n","Special tokens file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-2296/special_tokens_map.json\n","Deleting older checkpoint [/content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-1148] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: icd_code, icd_name, patient_id, context. If icd_code, icd_name, patient_id, context are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","07/21/2022 23:26:40 - INFO - __main__ - Performing evaluation...\n","***** Running Evaluation *****\n","  Num examples = 17340\n","  Batch size = 32\n","{'eval_loss': 0.3817254602909088, 'eval_threshold': 0.48, 'eval_accuracy': 0.06796116504854369, 'eval_f1_score_micro': 0.6248600223964165, 'eval_f1_score_macro': 0.4557209539215676, 'eval_f1_score_samples': 0.6217985535263889, 'eval_f1_score_weighted': 0.6617197507661149, 'eval_auc_score_micro': 0.9861745538295021, 'eval_auc_score_macro': 0.9784904295644157, 'eval_auc_score_samples': 0.9870163998979368, 'eval_auc_score_weighted': 0.9734707245229729, 'eval_targets_shape': (515, 170), 'eval_probs_shape': (515, 170), 'eval_precision@1': 0.8233009708737864, 'eval_precision@5': 0.49281553398058253, 'eval_precision@8': 0.37597087378640776, 'eval_precision@10': 0.32174757281553396, 'eval_precision@15': 0.23443365695792884, 'eval_precision@20': 0.18485436893203883, 'eval_recall@1': 0.3514486312812833, 'eval_recall@5': 0.7579897112766301, 'eval_recall@8': 0.8630483140319625, 'eval_recall@10': 0.8997429641272258, 'eval_recall@15': 0.9463809573722706, 'eval_recall@20': 0.969355999136275, 'epoch': 3.0}\n","Saving model checkpoint to /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-3444\n","Configuration saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-3444/config.json\n","Model weights saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-3444/pytorch_model.bin\n","tokenizer config file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-3444/tokenizer_config.json\n","Special tokens file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-3444/special_tokens_map.json\n","Deleting older checkpoint [/content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-2296] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: icd_code, icd_name, patient_id, context. If icd_code, icd_name, patient_id, context are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","07/21/2022 23:47:18 - INFO - __main__ - Performing evaluation...\n","***** Running Evaluation *****\n","  Num examples = 17340\n","  Batch size = 32\n","{'eval_loss': 0.22568468749523163, 'eval_threshold': 0.4, 'eval_accuracy': 0.15145631067961166, 'eval_f1_score_micro': 0.6761864762704747, 'eval_f1_score_macro': 0.46151040158880713, 'eval_f1_score_samples': 0.677630437844897, 'eval_f1_score_weighted': 0.6872464103670379, 'eval_auc_score_micro': 0.9871060477473156, 'eval_auc_score_macro': 0.978151961314543, 'eval_auc_score_samples': 0.98774070066962, 'eval_auc_score_weighted': 0.9771685108312789, 'eval_targets_shape': (515, 170), 'eval_probs_shape': (515, 170), 'eval_precision@1': 0.8951456310679612, 'eval_precision@5': 0.5067961165048543, 'eval_precision@8': 0.38058252427184464, 'eval_precision@10': 0.32757281553398054, 'eval_precision@15': 0.23572815533980584, 'eval_precision@20': 0.18514563106796114, 'eval_recall@1': 0.37921403200784903, 'eval_recall@5': 0.7758444687941366, 'eval_recall@8': 0.8660164496265671, 'eval_recall@10': 0.9039976475860482, 'eval_recall@15': 0.9457756538300739, 'eval_recall@20': 0.969474870357599, 'epoch': 4.0}\n","Saving model checkpoint to /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-4592\n","Configuration saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-4592/config.json\n","Model weights saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-4592/pytorch_model.bin\n","tokenizer config file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-4592/tokenizer_config.json\n","Special tokens file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-4592/special_tokens_map.json\n","Deleting older checkpoint [/content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-3444] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: icd_code, icd_name, patient_id, context. If icd_code, icd_name, patient_id, context are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","07/22/2022 00:07:55 - INFO - __main__ - Performing evaluation...\n","***** Running Evaluation *****\n","  Num examples = 17340\n","  Batch size = 32\n","{'eval_loss': 0.3204735815525055, 'eval_threshold': 0.62, 'eval_accuracy': 0.13592233009708737, 'eval_f1_score_micro': 0.6598505701926858, 'eval_f1_score_macro': 0.4728287085255523, 'eval_f1_score_samples': 0.6674532911758122, 'eval_f1_score_weighted': 0.6940127746178653, 'eval_auc_score_micro': 0.9879876818813574, 'eval_auc_score_macro': 0.9790586326264316, 'eval_auc_score_samples': 0.9888564557606837, 'eval_auc_score_weighted': 0.9784121546367839, 'eval_targets_shape': (515, 170), 'eval_probs_shape': (515, 170), 'eval_precision@1': 0.8815533980582524, 'eval_precision@5': 0.5071844660194176, 'eval_precision@8': 0.38276699029126215, 'eval_precision@10': 0.32699029126213586, 'eval_precision@15': 0.23779935275080907, 'eval_precision@20': 0.18514563106796114, 'eval_recall@1': 0.3809639164276364, 'eval_recall@5': 0.780679836685202, 'eval_recall@8': 0.8725569371864722, 'eval_recall@10': 0.9091800541762217, 'eval_recall@15': 0.9516992411154394, 'eval_recall@20': 0.9708957788365044, 'epoch': 5.0}\n","Saving model checkpoint to /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-5740\n","Configuration saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-5740/config.json\n","Model weights saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-5740/pytorch_model.bin\n","tokenizer config file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-5740/tokenizer_config.json\n","Special tokens file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-5740/special_tokens_map.json\n","Deleting older checkpoint [/content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-4592] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: icd_code, icd_name, patient_id, context. If icd_code, icd_name, patient_id, context are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","07/22/2022 00:28:33 - INFO - __main__ - Performing evaluation...\n","***** Running Evaluation *****\n","  Num examples = 17340\n","  Batch size = 32\n","{'eval_loss': 0.26006394624710083, 'eval_threshold': 0.52, 'eval_accuracy': 0.19223300970873786, 'eval_f1_score_micro': 0.6885245901639344, 'eval_f1_score_macro': 0.469585939453443, 'eval_f1_score_samples': 0.6982329264458995, 'eval_f1_score_weighted': 0.6931832252039344, 'eval_auc_score_micro': 0.9877415163032116, 'eval_auc_score_macro': 0.9789752963510308, 'eval_auc_score_samples': 0.988487898534021, 'eval_auc_score_weighted': 0.9787483096361603, 'eval_targets_shape': (515, 170), 'eval_probs_shape': (515, 170), 'eval_precision@1': 0.9009708737864077, 'eval_precision@5': 0.5075728155339807, 'eval_precision@8': 0.38349514563106796, 'eval_precision@10': 0.32504854368932035, 'eval_precision@15': 0.23702265372168288, 'eval_precision@20': 0.18533980582524273, 'eval_recall@1': 0.3875735635227204, 'eval_recall@5': 0.7829543835203007, 'eval_recall@8': 0.8719951240492885, 'eval_recall@10': 0.9022699372392781, 'eval_recall@15': 0.9480464241373796, 'eval_recall@20': 0.9714271541494331, 'epoch': 6.0}\n","Saving model checkpoint to /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-6888\n","Configuration saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-6888/config.json\n","Model weights saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-6888/pytorch_model.bin\n","tokenizer config file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-6888/tokenizer_config.json\n","Special tokens file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-6888/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: icd_code, icd_name, patient_id, context. If icd_code, icd_name, patient_id, context are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","07/22/2022 00:49:12 - INFO - __main__ - Performing evaluation...\n","***** Running Evaluation *****\n","  Num examples = 17340\n","  Batch size = 32\n","{'eval_loss': 0.3468434512615204, 'eval_threshold': 0.87, 'eval_accuracy': 0.1883495145631068, 'eval_f1_score_micro': 0.6710935878813031, 'eval_f1_score_macro': 0.47090067093728016, 'eval_f1_score_samples': 0.6829774020603564, 'eval_f1_score_weighted': 0.6913982048957612, 'eval_auc_score_micro': 0.9882600580544384, 'eval_auc_score_macro': 0.9788007489400918, 'eval_auc_score_samples': 0.9886492543720635, 'eval_auc_score_weighted': 0.9786239437913629, 'eval_targets_shape': (515, 170), 'eval_probs_shape': (515, 170), 'eval_precision@1': 0.9048543689320389, 'eval_precision@5': 0.512621359223301, 'eval_precision@8': 0.383252427184466, 'eval_precision@10': 0.3271844660194175, 'eval_precision@15': 0.23559870550161813, 'eval_precision@20': 0.1855339805825243, 'eval_recall@1': 0.3850516032823135, 'eval_recall@5': 0.7843849789851323, 'eval_recall@8': 0.8754332033151655, 'eval_recall@10': 0.9056355906343132, 'eval_recall@15': 0.9451198163104142, 'eval_recall@20': 0.9700990422170801, 'epoch': 7.0}\n","Saving model checkpoint to /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-8036\n","Configuration saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-8036/config.json\n","Model weights saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-8036/pytorch_model.bin\n","tokenizer config file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-8036/tokenizer_config.json\n","Special tokens file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-8036/special_tokens_map.json\n","Deleting older checkpoint [/content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-6888] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: icd_code, icd_name, patient_id, context. If icd_code, icd_name, patient_id, context are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","07/22/2022 01:09:50 - INFO - __main__ - Performing evaluation...\n","***** Running Evaluation *****\n","  Num examples = 17340\n","  Batch size = 32\n","{'eval_loss': 0.2979912757873535, 'eval_threshold': 0.62, 'eval_accuracy': 0.2, 'eval_f1_score_micro': 0.6960122030943561, 'eval_f1_score_macro': 0.4808881446630509, 'eval_f1_score_samples': 0.7032390489353492, 'eval_f1_score_weighted': 0.7089337536671176, 'eval_auc_score_micro': 0.9874509396947222, 'eval_auc_score_macro': 0.9767304616686928, 'eval_auc_score_samples': 0.9876623965281567, 'eval_auc_score_weighted': 0.9784858672838594, 'eval_targets_shape': (515, 170), 'eval_probs_shape': (515, 170), 'eval_precision@1': 0.8970873786407767, 'eval_precision@5': 0.5137864077669904, 'eval_precision@8': 0.38519417475728157, 'eval_precision@10': 0.3264077669902912, 'eval_precision@15': 0.23611650485436894, 'eval_precision@20': 0.18436893203883495, 'eval_recall@1': 0.38642700781305794, 'eval_recall@5': 0.785389178045029, 'eval_recall@8': 0.8739419329889437, 'eval_recall@10': 0.9011667029104433, 'eval_recall@15': 0.9392640189254905, 'eval_recall@20': 0.9598754470420287, 'epoch': 8.0}\n","Saving model checkpoint to /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-9184\n","Configuration saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-9184/config.json\n","Model weights saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-9184/pytorch_model.bin\n","tokenizer config file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-9184/tokenizer_config.json\n","Special tokens file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-9184/special_tokens_map.json\n","Deleting older checkpoint [/content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-5740] due to args.save_total_limit\n","Deleting older checkpoint [/content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-8036] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: icd_code, icd_name, patient_id, context. If icd_code, icd_name, patient_id, context are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","07/22/2022 01:30:28 - INFO - __main__ - Performing evaluation...\n","***** Running Evaluation *****\n","  Num examples = 17340\n","  Batch size = 32\n","{'eval_loss': 0.3114781677722931, 'eval_threshold': 0.64, 'eval_accuracy': 0.14951456310679612, 'eval_f1_score_micro': 0.6792452830188679, 'eval_f1_score_macro': 0.48844638180328576, 'eval_f1_score_samples': 0.6855819815632169, 'eval_f1_score_weighted': 0.7030942132285679, 'eval_auc_score_micro': 0.98755756245157, 'eval_auc_score_macro': 0.9764380962812588, 'eval_auc_score_samples': 0.9886207849896939, 'eval_auc_score_weighted': 0.9771500689519536, 'eval_targets_shape': (515, 170), 'eval_probs_shape': (515, 170), 'eval_precision@1': 0.912621359223301, 'eval_precision@5': 0.5137864077669904, 'eval_precision@8': 0.3883495145631068, 'eval_precision@10': 0.32873786407766986, 'eval_precision@15': 0.23624595469255666, 'eval_precision@20': 0.18524271844660192, 'eval_recall@1': 0.39548849648619705, 'eval_recall@5': 0.7852062774277899, 'eval_recall@8': 0.8771811172986442, 'eval_recall@10': 0.9059162090677164, 'eval_recall@15': 0.9461676250281258, 'eval_recall@20': 0.967420607553464, 'epoch': 9.0}\n","Saving model checkpoint to /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-10332\n","Configuration saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-10332/config.json\n","Model weights saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-10332/pytorch_model.bin\n","tokenizer config file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-10332/tokenizer_config.json\n","Special tokens file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-10332/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: icd_code, icd_name, patient_id, context. If icd_code, icd_name, patient_id, context are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","07/22/2022 01:51:05 - INFO - __main__ - Performing evaluation...\n","***** Running Evaluation *****\n","  Num examples = 17340\n","  Batch size = 32\n","{'eval_loss': 0.27319449186325073, 'eval_threshold': 0.57, 'eval_accuracy': 0.18446601941747573, 'eval_f1_score_micro': 0.6947996589940325, 'eval_f1_score_macro': 0.4866123542384604, 'eval_f1_score_samples': 0.6989929164500656, 'eval_f1_score_weighted': 0.714004489693578, 'eval_auc_score_micro': 0.9880311919609364, 'eval_auc_score_macro': 0.9780723051546127, 'eval_auc_score_samples': 0.9886445466814405, 'eval_auc_score_weighted': 0.9788947411674416, 'eval_targets_shape': (515, 170), 'eval_probs_shape': (515, 170), 'eval_precision@1': 0.9029126213592233, 'eval_precision@5': 0.5196116504854369, 'eval_precision@8': 0.3888349514563107, 'eval_precision@10': 0.3289320388349515, 'eval_precision@15': 0.2361165048543689, 'eval_precision@20': 0.18524271844660195, 'eval_recall@1': 0.38418937489581334, 'eval_recall@5': 0.7890389172798473, 'eval_recall@8': 0.8762989502974173, 'eval_recall@10': 0.9039721013954534, 'eval_recall@15': 0.9418703840586824, 'eval_recall@20': 0.9689370855965134, 'epoch': 10.0}\n","Saving model checkpoint to /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-11480\n","Configuration saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-11480/config.json\n","Model weights saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-11480/pytorch_model.bin\n","tokenizer config file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-11480/tokenizer_config.json\n","Special tokens file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-11480/special_tokens_map.json\n","Deleting older checkpoint [/content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-9184] due to args.save_total_limit\n","Deleting older checkpoint [/content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-10332] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: icd_code, icd_name, patient_id, context. If icd_code, icd_name, patient_id, context are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","07/22/2022 02:11:43 - INFO - __main__ - Performing evaluation...\n","***** Running Evaluation *****\n","  Num examples = 17340\n","  Batch size = 32\n","{'eval_loss': 0.28134140372276306, 'eval_threshold': 0.74, 'eval_accuracy': 0.20776699029126214, 'eval_f1_score_micro': 0.6929765886287625, 'eval_f1_score_macro': 0.47108267966304707, 'eval_f1_score_samples': 0.7003299564641902, 'eval_f1_score_weighted': 0.6975751220398152, 'eval_auc_score_micro': 0.9872108901270557, 'eval_auc_score_macro': 0.9768711364318076, 'eval_auc_score_samples': 0.9882194797090664, 'eval_auc_score_weighted': 0.977227353422098, 'eval_targets_shape': (515, 170), 'eval_probs_shape': (515, 170), 'eval_precision@1': 0.9029126213592233, 'eval_precision@5': 0.5114563106796117, 'eval_precision@8': 0.37839805825242717, 'eval_precision@10': 0.3266019417475728, 'eval_precision@15': 0.23650485436893207, 'eval_precision@20': 0.18563106796116505, 'eval_recall@1': 0.387236069301731, 'eval_recall@5': 0.7769785073553597, 'eval_recall@8': 0.8611308255419139, 'eval_recall@10': 0.9009123563939611, 'eval_recall@15': 0.9462021509121663, 'eval_recall@20': 0.9706125820752801, 'epoch': 11.0}\n","Saving model checkpoint to /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-12628\n","Configuration saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-12628/config.json\n","Model weights saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-12628/pytorch_model.bin\n","tokenizer config file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-12628/tokenizer_config.json\n","Special tokens file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-12628/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: icd_code, icd_name, patient_id, context. If icd_code, icd_name, patient_id, context are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","07/22/2022 02:32:21 - INFO - __main__ - Performing evaluation...\n","***** Running Evaluation *****\n","  Num examples = 17340\n","  Batch size = 32\n","{'eval_loss': 0.2960374653339386, 'eval_threshold': 0.76, 'eval_accuracy': 0.20388349514563106, 'eval_f1_score_micro': 0.6991905491139795, 'eval_f1_score_macro': 0.49048531921986865, 'eval_f1_score_samples': 0.708781662995694, 'eval_f1_score_weighted': 0.7052762840847442, 'eval_auc_score_micro': 0.988008077807707, 'eval_auc_score_macro': 0.9780265524177159, 'eval_auc_score_samples': 0.9886179581279697, 'eval_auc_score_weighted': 0.9787109633398696, 'eval_targets_shape': (515, 170), 'eval_probs_shape': (515, 170), 'eval_precision@1': 0.9048543689320389, 'eval_precision@5': 0.5207766990291263, 'eval_precision@8': 0.3864077669902913, 'eval_precision@10': 0.32699029126213586, 'eval_precision@15': 0.23624595469255663, 'eval_precision@20': 0.18553398058252427, 'eval_recall@1': 0.3876244188162941, 'eval_recall@5': 0.7898333386082491, 'eval_recall@8': 0.8736585647929541, 'eval_recall@10': 0.9024657544522133, 'eval_recall@15': 0.9449083530164266, 'eval_recall@20': 0.9697763865329015, 'epoch': 12.0}\n","Saving model checkpoint to /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-13776\n","Configuration saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-13776/config.json\n","Model weights saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-13776/pytorch_model.bin\n","tokenizer config file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-13776/tokenizer_config.json\n","Special tokens file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-13776/special_tokens_map.json\n","Deleting older checkpoint [/content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-12628] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: icd_code, icd_name, patient_id, context. If icd_code, icd_name, patient_id, context are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","07/22/2022 02:52:59 - INFO - __main__ - Performing evaluation...\n","***** Running Evaluation *****\n","  Num examples = 17340\n","  Batch size = 32\n","{'eval_loss': 0.3492777943611145, 'eval_threshold': 0.86, 'eval_accuracy': 0.18446601941747573, 'eval_f1_score_micro': 0.7026200873362446, 'eval_f1_score_macro': 0.4973993898951765, 'eval_f1_score_samples': 0.7060871663578893, 'eval_f1_score_weighted': 0.7155986256314611, 'eval_auc_score_micro': 0.9874639957935132, 'eval_auc_score_macro': 0.9766135361106946, 'eval_auc_score_samples': 0.9879372672488175, 'eval_auc_score_weighted': 0.9772710582770184, 'eval_targets_shape': (515, 170), 'eval_probs_shape': (515, 170), 'eval_precision@1': 0.8932038834951457, 'eval_precision@5': 0.5153398058252426, 'eval_precision@8': 0.38519417475728157, 'eval_precision@10': 0.32757281553398054, 'eval_precision@15': 0.23637540453074438, 'eval_precision@20': 0.18485436893203883, 'eval_recall@1': 0.38312603693927144, 'eval_recall@5': 0.7850436245466905, 'eval_recall@8': 0.8711525971898991, 'eval_recall@10': 0.9017553914602969, 'eval_recall@15': 0.943004729756135, 'eval_recall@20': 0.9619779757516088, 'epoch': 13.0}\n","Saving model checkpoint to /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-14924\n","Configuration saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-14924/config.json\n","Model weights saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-14924/pytorch_model.bin\n","tokenizer config file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-14924/tokenizer_config.json\n","Special tokens file saved in /content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-14924/special_tokens_map.json\n","Deleting older checkpoint [/content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-11480] due to args.save_total_limit\n","Deleting older checkpoint [/content/tmp/michiyasunaga/BioLinkBERT-base/non-sup-tune-after-pretrain/checkpoint-13776] due to args.save_total_limit\n"]}],"source":["# !python train.py --model_name=microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext \\\n","!python train.py --model_name=michiyasunaga/BioLinkBERT-base \\\n","                 --experiment_name=$EXPERIMENT_NAME \\\n","                 --num_train_epochs=$NUM_EPOCHS \\\n","                 --data_dir=$DS_HOME \\\n","                 --model_dir=$MODEL_HOME_PRETRAIN \\\n","                 --is_pretrain=False\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ByYirdeJ9qNv"},"outputs":[],"source":["drive.flush_and_unmount()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HF5nYQ2Tt3Nn"},"outputs":[],"source":["123"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZLjWxCkwEw39"},"outputs":[],"source":["\"\"\"\n","TODO:\n","make copy of pretrained model's checkpoint\n","tune pretrained model on 4 char codes\n","evaluate pretrained model on 5 char codes\n","---\n","pretrain on 4 char codes\n","tune on 5 char codes\n","evaluate on 5 char codes\n","\"\"\""]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"train (pretrain).ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.1 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.1"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
