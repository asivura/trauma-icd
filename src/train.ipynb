{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":248,"status":"ok","timestamp":1657686910716,"user":{"displayName":"Alexander Sivura","userId":"10766689953915275175"},"user_tz":420},"id":"cmsGhOs4vAuA","outputId":"75b1662b-ccb1-47dc-d793-f7c49240844c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wed Jul 13 04:35:10 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29630,"status":"ok","timestamp":1657670874021,"user":{"displayName":"Alexander Sivura","userId":"10766689953915275175"},"user_tz":420},"id":"alLOMYe2UgeF","outputId":"cb759ba8-ada3-43d2-a77d-acc43b88e730"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |████████████████████████████████| 362 kB 14.2 MB/s \n","\u001b[K     |████████████████████████████████| 140 kB 87.4 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 76.1 MB/s \n","\u001b[K     |████████████████████████████████| 101 kB 9.5 MB/s \n","\u001b[K     |████████████████████████████████| 212 kB 67.2 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 76.3 MB/s \n","\u001b[K     |████████████████████████████████| 127 kB 87.1 MB/s \n","\u001b[K     |████████████████████████████████| 271 kB 97.2 MB/s \n","\u001b[K     |████████████████████████████████| 94 kB 3.6 MB/s \n","\u001b[K     |████████████████████████████████| 144 kB 91.1 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 4.4 MB 14.8 MB/s \n","\u001b[K     |████████████████████████████████| 6.6 MB 86.1 MB/s \n","\u001b[K     |████████████████████████████████| 1.8 MB 14.6 MB/s \n","\u001b[K     |████████████████████████████████| 181 kB 84.5 MB/s \n","\u001b[K     |████████████████████████████████| 146 kB 80.2 MB/s \n","\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install datasets -q\n","!pip install transformers -q -U\n","!pip install wandb -q -U"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Zeo0Kk5WV9L"},"outputs":[],"source":["import pandas as pd\n","import datasets\n","import sys, importlib\n","import random\n","\n","import shutil"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":359868,"status":"ok","timestamp":1657671234455,"user":{"displayName":"Alexander Sivura","userId":"10766689953915275175"},"user_tz":420},"id":"IZItXZ1SMjK1","outputId":"35098508-a74d-41c5-b443-97d2fc8bdd2a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["import os\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive')\n","DS_HOME = '/content/gdrive/Shareddrives/cs224n-final-project/injury-icd-dataset'\n","CODE_HOME = '/content/gdrive/Shareddrives/cs224n-final-project/code'\n","CODE_HOME_PRETRAIN = '/content/gdrive/Shareddrives/cs224n-final-project/code'\n","TMP_DIR = '/content/tmp'\n","\n","if not os.path.exists(TMP_DIR):\n","    os.mkdir(TMP_DIR)\n","\n","os.chdir(CODE_HOME)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H4ASD5mMREhq"},"outputs":[],"source":["# !rm -rf /content/gdrive/Shareddrives/cs224n-final-project/models/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext/encoded_ds"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"pKyvh5MMOLo7","outputId":"68770448-69be-4709-c071-de7a15b8acec"},"outputs":[{"name":"stdout","output_type":"stream","text":["07/13/2022 04:36:24 - WARNING - __main__ - Loading base model microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext...\n","07/13/2022 04:36:28 - WARNING - __main__ - Training...\n","{'eval_loss': 0.37942254543304443, 'eval_threshold': 0.44, 'eval_accuracy': 0.040776699029126215, 'eval_f1_score_micro': 0.545273301212826, 'eval_f1_score_macro': 0.4163068737047819, 'eval_f1_score_samples': 0.5380865671226294, 'eval_f1_score_weighted': 0.6182492397556602, 'eval_auc_score_micro': 0.9818351137104412, 'eval_auc_score_macro': 0.9735407006298016, 'eval_auc_score_samples': 0.9827196423554894, 'eval_auc_score_weighted': 0.9680348200883254, 'eval_precision@1': 0.7864077669902912, 'eval_precision@5': 0.4512621359223301, 'eval_precision@8': 0.34951456310679613, 'eval_precision@10': 0.30213592233009706, 'eval_precision@15': 0.2271844660194175, 'eval_recall@1': 0.33778782067872515, 'eval_recall@5': 0.714974246783138, 'eval_recall@8': 0.8192443122936225, 'eval_recall@10': 0.8601147272928059, 'eval_recall@15': 0.9257576314845095, 'epoch': 1.0}\n","{'eval_loss': 0.32216644287109375, 'eval_threshold': 0.58, 'eval_accuracy': 0.04854368932038835, 'eval_f1_score_micro': 0.6093720356668565, 'eval_f1_score_macro': 0.44940943388255034, 'eval_f1_score_samples': 0.5944395718100635, 'eval_f1_score_weighted': 0.6449149694760965, 'eval_auc_score_micro': 0.9849374838566842, 'eval_auc_score_macro': 0.9757192731717994, 'eval_auc_score_samples': 0.9854333341901159, 'eval_auc_score_weighted': 0.9737169088484803, 'eval_precision@1': 0.8466019417475729, 'eval_precision@5': 0.47611650485436896, 'eval_precision@8': 0.36650485436893204, 'eval_precision@10': 0.3163106796116505, 'eval_precision@15': 0.2332686084142395, 'eval_recall@1': 0.3592101793340935, 'eval_recall@5': 0.7391530220758631, 'eval_recall@8': 0.845125006572375, 'eval_recall@10': 0.8840622593496891, 'eval_recall@15': 0.9400445446791896, 'epoch': 2.0}\n","{'eval_loss': 0.321859210729599, 'eval_threshold': 0.23, 'eval_accuracy': 0.02524271844660194, 'eval_f1_score_micro': 0.5828493337888623, 'eval_f1_score_macro': 0.4453198366538398, 'eval_f1_score_samples': 0.5705993849372119, 'eval_f1_score_weighted': 0.6432445549904645, 'eval_auc_score_micro': 0.9853703830116969, 'eval_auc_score_macro': 0.9767498405617075, 'eval_auc_score_samples': 0.9861346135339221, 'eval_auc_score_weighted': 0.9757851154286225, 'eval_precision@1': 0.8524271844660194, 'eval_precision@5': 0.48000000000000004, 'eval_precision@8': 0.3711165048543689, 'eval_precision@10': 0.31961165048543694, 'eval_precision@15': 0.23430420711974112, 'eval_recall@1': 0.3630173915393639, 'eval_recall@5': 0.7453543386438123, 'eval_recall@8': 0.8534791271863321, 'eval_recall@10': 0.8937901339562044, 'eval_recall@15': 0.9447820338124375, 'epoch': 3.0}\n","{'eval_loss': 0.2583983242511749, 'eval_threshold': 0.58, 'eval_accuracy': 0.141747572815534, 'eval_f1_score_micro': 0.651238992422691, 'eval_f1_score_macro': 0.45156713252518543, 'eval_f1_score_samples': 0.6510574560139181, 'eval_f1_score_weighted': 0.6762817198747052, 'eval_auc_score_micro': 0.9864899204211406, 'eval_auc_score_macro': 0.9784466100169645, 'eval_auc_score_samples': 0.9872942786980335, 'eval_auc_score_weighted': 0.9772691435492383, 'eval_precision@1': 0.8718446601941747, 'eval_precision@5': 0.494368932038835, 'eval_precision@8': 0.3774271844660194, 'eval_precision@10': 0.3213592233009709, 'eval_precision@15': 0.23676375404530745, 'eval_recall@1': 0.3658537299582266, 'eval_recall@5': 0.7638132206463836, 'eval_recall@8': 0.8613294052793287, 'eval_recall@10': 0.8943771800504043, 'eval_recall@15': 0.9498756305296928, 'epoch': 4.0}\n","{'eval_loss': 0.3233207166194916, 'eval_threshold': 0.72, 'eval_accuracy': 0.14757281553398058, 'eval_f1_score_micro': 0.6518282988871225, 'eval_f1_score_macro': 0.46455231203479297, 'eval_f1_score_samples': 0.6563274336447827, 'eval_f1_score_weighted': 0.6852949845870786, 'eval_auc_score_micro': 0.987389779589929, 'eval_auc_score_macro': 0.97880093205387, 'eval_auc_score_samples': 0.9878880633656034, 'eval_auc_score_weighted': 0.9769284645165346, 'eval_precision@1': 0.8737864077669902, 'eval_precision@5': 0.4966990291262136, 'eval_precision@8': 0.3781553398058252, 'eval_precision@10': 0.3244660194174757, 'eval_precision@15': 0.2362459546925566, 'eval_recall@1': 0.3703427253210084, 'eval_recall@5': 0.7653796477467913, 'eval_recall@8': 0.8626225592666573, 'eval_recall@10': 0.9013520121223237, 'eval_recall@15': 0.9454538855228686, 'epoch': 5.0}\n","{'eval_loss': 0.31320664286613464, 'eval_threshold': 0.45, 'eval_accuracy': 0.141747572815534, 'eval_f1_score_micro': 0.6598943518894759, 'eval_f1_score_macro': 0.4634041710340899, 'eval_f1_score_samples': 0.6583708649368952, 'eval_f1_score_weighted': 0.6832217883615996, 'eval_auc_score_micro': 0.9867857274639313, 'eval_auc_score_macro': 0.9777159909671816, 'eval_auc_score_samples': 0.9878563881643023, 'eval_auc_score_weighted': 0.977635310416163, 'eval_precision@1': 0.8815533980582524, 'eval_precision@5': 0.4974757281553398, 'eval_precision@8': 0.37839805825242717, 'eval_precision@10': 0.32485436893203884, 'eval_precision@15': 0.23559870550161813, 'eval_recall@1': 0.3734395745343625, 'eval_recall@5': 0.7661477523498473, 'eval_recall@8': 0.8634266122794482, 'eval_recall@10': 0.9043056513406539, 'eval_recall@15': 0.9444077192608108, 'epoch': 6.0}\n","{'eval_loss': 0.361612468957901, 'eval_threshold': 0.78, 'eval_accuracy': 0.12427184466019417, 'eval_f1_score_micro': 0.646921278254092, 'eval_f1_score_macro': 0.4641760280356712, 'eval_f1_score_samples': 0.6564997766258458, 'eval_f1_score_weighted': 0.6831588100838349, 'eval_auc_score_micro': 0.9875310228404856, 'eval_auc_score_macro': 0.9780336707119328, 'eval_auc_score_samples': 0.9882592145200525, 'eval_auc_score_weighted': 0.9785680574378294, 'eval_precision@1': 0.8932038834951457, 'eval_precision@5': 0.5079611650485437, 'eval_precision@8': 0.38033980582524274, 'eval_precision@10': 0.3267961165048544, 'eval_precision@15': 0.23663430420711976, 'eval_recall@1': 0.3761881420402115, 'eval_recall@5': 0.7793441190899034, 'eval_recall@8': 0.8700720111093131, 'eval_recall@10': 0.9068193242912201, 'eval_recall@15': 0.9479798446316076, 'epoch': 7.0}\n","{'eval_loss': 0.32653266191482544, 'eval_threshold': 0.68, 'eval_accuracy': 0.1436893203883495, 'eval_f1_score_micro': 0.6562749800159873, 'eval_f1_score_macro': 0.4735633505715308, 'eval_f1_score_samples': 0.664866115584224, 'eval_f1_score_weighted': 0.6873050673213815, 'eval_auc_score_micro': 0.9875466311206229, 'eval_auc_score_macro': 0.9780083239974657, 'eval_auc_score_samples': 0.9886053956032307, 'eval_auc_score_weighted': 0.9781601402596347, 'eval_precision@1': 0.9067961165048544, 'eval_precision@5': 0.5106796116504855, 'eval_precision@8': 0.3808252427184466, 'eval_precision@10': 0.3260194174757281, 'eval_precision@15': 0.23754045307443367, 'eval_recall@1': 0.38739325839095895, 'eval_recall@5': 0.7830218814569861, 'eval_recall@8': 0.8694728017965114, 'eval_recall@10': 0.9042702373706462, 'eval_recall@15': 0.9480969443603579, 'epoch': 8.0}\n","{'eval_loss': 0.34758955240249634, 'eval_threshold': 0.42, 'eval_accuracy': 0.13009708737864079, 'eval_f1_score_micro': 0.657389259114073, 'eval_f1_score_macro': 0.47425856745985845, 'eval_f1_score_samples': 0.6586188177595231, 'eval_f1_score_weighted': 0.6896356460039091, 'eval_auc_score_micro': 0.987353006654121, 'eval_auc_score_macro': 0.9778919950733197, 'eval_auc_score_samples': 0.9880281398957426, 'eval_auc_score_weighted': 0.9780134845795743, 'eval_precision@1': 0.8951456310679612, 'eval_precision@5': 0.5075728155339806, 'eval_precision@8': 0.38228155339805825, 'eval_precision@10': 0.3254368932038834, 'eval_precision@15': 0.23637540453074438, 'eval_recall@1': 0.37864152468776896, 'eval_recall@5': 0.7743234331954311, 'eval_recall@8': 0.8710686277612696, 'eval_recall@10': 0.902347613069381, 'eval_recall@15': 0.9443212055360752, 'epoch': 9.0}\n","{'eval_loss': 0.329853892326355, 'eval_threshold': 0.31, 'eval_accuracy': 0.14563106796116504, 'eval_f1_score_micro': 0.6639967961553864, 'eval_f1_score_macro': 0.4760010068936709, 'eval_f1_score_samples': 0.6731900534781675, 'eval_f1_score_weighted': 0.6959179833649479, 'eval_auc_score_micro': 0.986889044684698, 'eval_auc_score_macro': 0.9756545177549415, 'eval_auc_score_samples': 0.9876728367633184, 'eval_auc_score_weighted': 0.9776127451811754, 'eval_precision@1': 0.8932038834951457, 'eval_precision@5': 0.5071844660194175, 'eval_precision@8': 0.38228155339805825, 'eval_precision@10': 0.3266019417475728, 'eval_precision@15': 0.23663430420711976, 'eval_recall@1': 0.3771312765755791, 'eval_recall@5': 0.7764677128639826, 'eval_recall@8': 0.866132942172799, 'eval_recall@10': 0.9008517212362384, 'eval_recall@15': 0.9427419774060041, 'epoch': 10.0}\n","{'eval_loss': 0.33952900767326355, 'eval_threshold': 0.66, 'eval_accuracy': 0.14563106796116504, 'eval_f1_score_micro': 0.6758047767393562, 'eval_f1_score_macro': 0.47812969406949435, 'eval_f1_score_samples': 0.6761334662797533, 'eval_f1_score_weighted': 0.6983223101475486, 'eval_auc_score_micro': 0.9871336174556905, 'eval_auc_score_macro': 0.9759510263288028, 'eval_auc_score_samples': 0.988460627042886, 'eval_auc_score_weighted': 0.9778194186751679, 'eval_precision@1': 0.8796116504854369, 'eval_precision@5': 0.5157281553398058, 'eval_precision@8': 0.3849514563106796, 'eval_precision@10': 0.3283495145631068, 'eval_precision@15': 0.23741100323624595, 'eval_recall@1': 0.37489742628347633, 'eval_recall@5': 0.7824887414578268, 'eval_recall@8': 0.8740763832204813, 'eval_recall@10': 0.9042535351720329, 'eval_recall@15': 0.9467790227997177, 'epoch': 11.0}\n","{'eval_loss': 0.3668016195297241, 'eval_threshold': 0.78, 'eval_accuracy': 0.14563106796116504, 'eval_f1_score_micro': 0.6716263690845217, 'eval_f1_score_macro': 0.4705941706901339, 'eval_f1_score_samples': 0.6781053867937236, 'eval_f1_score_weighted': 0.6900033937717762, 'eval_auc_score_micro': 0.9869749547987159, 'eval_auc_score_macro': 0.9758561994571241, 'eval_auc_score_samples': 0.9883252390943759, 'eval_auc_score_weighted': 0.977667340395688, 'eval_precision@1': 0.8912621359223301, 'eval_precision@5': 0.513009708737864, 'eval_precision@8': 0.3856796116504854, 'eval_precision@10': 0.3271844660194175, 'eval_precision@15': 0.23546925566343044, 'eval_recall@1': 0.37751962609014217, 'eval_recall@5': 0.7796932413807732, 'eval_recall@8': 0.8708770528852287, 'eval_recall@10': 0.9032230015201401, 'eval_recall@15': 0.9432492516000437, 'epoch': 12.0}\n","{'eval_loss': 0.4329400360584259, 'eval_threshold': 0.95, 'eval_accuracy': 0.15922330097087378, 'eval_f1_score_micro': 0.6872340425531914, 'eval_f1_score_macro': 0.48474888009759126, 'eval_f1_score_samples': 0.6891772408786201, 'eval_f1_score_weighted': 0.7030956102449787, 'eval_auc_score_micro': 0.9872252868897827, 'eval_auc_score_macro': 0.9764529540523709, 'eval_auc_score_samples': 0.9880869166428773, 'eval_auc_score_weighted': 0.9779581873900012, 'eval_precision@1': 0.8893203883495145, 'eval_precision@5': 0.5122330097087379, 'eval_precision@8': 0.3849514563106796, 'eval_precision@10': 0.32757281553398054, 'eval_precision@15': 0.23650485436893207, 'eval_recall@1': 0.3795437508327136, 'eval_recall@5': 0.7778331004429625, 'eval_recall@8': 0.8747217761231558, 'eval_recall@10': 0.9035925816929905, 'eval_recall@15': 0.942698922748744, 'epoch': 13.0}\n","{'eval_loss': 0.3500481843948364, 'eval_threshold': 0.9, 'eval_accuracy': 0.15922330097087378, 'eval_f1_score_micro': 0.6896402254009536, 'eval_f1_score_macro': 0.47682537401082575, 'eval_f1_score_samples': 0.6913142457969524, 'eval_f1_score_weighted': 0.7010823656795608, 'eval_auc_score_micro': 0.9866856512059825, 'eval_auc_score_macro': 0.9749647141608042, 'eval_auc_score_samples': 0.9880700130112174, 'eval_auc_score_weighted': 0.9777923331186755, 'eval_precision@1': 0.8951456310679612, 'eval_precision@5': 0.5149514563106796, 'eval_precision@8': 0.3856796116504854, 'eval_precision@10': 0.32815533980582523, 'eval_precision@15': 0.23624595469255663, 'eval_recall@1': 0.37790797560470524, 'eval_recall@5': 0.7806070255469848, 'eval_recall@8': 0.8714084847758838, 'eval_recall@10': 0.9027741336900764, 'eval_recall@15': 0.9428334197738899, 'epoch': 14.0}\n","{'eval_loss': 0.41406503319740295, 'eval_threshold': 0.92, 'eval_accuracy': 0.13980582524271845, 'eval_f1_score_micro': 0.6813602015113349, 'eval_f1_score_macro': 0.48800947513608794, 'eval_f1_score_samples': 0.6854377572227659, 'eval_f1_score_weighted': 0.7037437976267207, 'eval_auc_score_micro': 0.986514027772653, 'eval_auc_score_macro': 0.9754632020663921, 'eval_auc_score_samples': 0.9880968141870402, 'eval_auc_score_weighted': 0.9778971062644026, 'eval_precision@1': 0.8990291262135922, 'eval_precision@5': 0.516116504854369, 'eval_precision@8': 0.3837378640776699, 'eval_precision@10': 0.32699029126213586, 'eval_precision@15': 0.2350809061488673, 'eval_recall@1': 0.38143548369532015, 'eval_recall@5': 0.7842693772190451, 'eval_recall@8': 0.8696422224513691, 'eval_recall@10': 0.9006607983511407, 'eval_recall@15': 0.939016239112049, 'epoch': 15.0}\n","{'eval_loss': 0.3816136419773102, 'eval_threshold': 0.43, 'eval_accuracy': 0.13592233009708737, 'eval_f1_score_micro': 0.6743091095189356, 'eval_f1_score_macro': 0.488442256135653, 'eval_f1_score_samples': 0.6772213962594842, 'eval_f1_score_weighted': 0.7023033801712656, 'eval_auc_score_micro': 0.9864639219954984, 'eval_auc_score_macro': 0.9753974726506466, 'eval_auc_score_samples': 0.9879250961499556, 'eval_auc_score_weighted': 0.977275350852147, 'eval_precision@1': 0.9009708737864077, 'eval_precision@5': 0.5149514563106796, 'eval_precision@8': 0.3837378640776699, 'eval_precision@10': 0.3267961165048544, 'eval_precision@15': 0.23533980582524275, 'eval_recall@1': 0.3803890975033029, 'eval_recall@5': 0.7779872073931858, 'eval_recall@8': 0.8687620131245577, 'eval_recall@10': 0.9011987797871804, 'eval_recall@15': 0.9392141227590896, 'epoch': 16.0}\n","{'eval_loss': 0.37050947546958923, 'eval_threshold': 0.58, 'eval_accuracy': 0.14563106796116504, 'eval_f1_score_micro': 0.6824887748556767, 'eval_f1_score_macro': 0.47836989337609853, 'eval_f1_score_samples': 0.6831399915471493, 'eval_f1_score_weighted': 0.6995425471371981, 'eval_auc_score_micro': 0.9862899923742051, 'eval_auc_score_macro': 0.9749547023076273, 'eval_auc_score_samples': 0.9879364860828457, 'eval_auc_score_weighted': 0.9774294106403602, 'eval_precision@1': 0.8912621359223301, 'eval_precision@5': 0.5176699029126214, 'eval_precision@8': 0.383252427184466, 'eval_precision@10': 0.3264077669902912, 'eval_precision@15': 0.2348220064724919, 'eval_recall@1': 0.37569654086899873, 'eval_recall@5': 0.785964553671503, 'eval_recall@8': 0.8689427735723085, 'eval_recall@10': 0.8998036036807114, 'eval_recall@15': 0.9405904901037758, 'epoch': 17.0}\n","{'eval_loss': 0.39909401535987854, 'eval_threshold': 0.87, 'eval_accuracy': 0.15922330097087378, 'eval_f1_score_micro': 0.6878260869565217, 'eval_f1_score_macro': 0.4778351077899664, 'eval_f1_score_samples': 0.6874708290146117, 'eval_f1_score_weighted': 0.7013559755804346, 'eval_auc_score_micro': 0.9865631188271036, 'eval_auc_score_macro': 0.9756047603022782, 'eval_auc_score_samples': 0.9879278145065189, 'eval_auc_score_weighted': 0.9776345115322657, 'eval_precision@1': 0.9009708737864077, 'eval_precision@5': 0.5196116504854369, 'eval_precision@8': 0.3866504854368932, 'eval_precision@10': 0.3283495145631068, 'eval_precision@15': 0.23559870550161813, 'eval_recall@1': 0.3804214599628499, 'eval_recall@5': 0.7872467234973621, 'eval_recall@8': 0.8733294764056134, 'eval_recall@10': 0.902095612188867, 'eval_recall@15': 0.9408052069715329, 'epoch': 18.0}\n","{'eval_loss': 0.4010062515735626, 'eval_threshold': 0.92, 'eval_accuracy': 0.16310679611650486, 'eval_f1_score_micro': 0.6928822495606326, 'eval_f1_score_macro': 0.4801849918848297, 'eval_f1_score_samples': 0.6931978926445435, 'eval_f1_score_weighted': 0.7035930096059013, 'eval_auc_score_micro': 0.9866879850682017, 'eval_auc_score_macro': 0.9754690190489682, 'eval_auc_score_samples': 0.9879599476696747, 'eval_auc_score_weighted': 0.9778938692160968, 'eval_precision@1': 0.8990291262135922, 'eval_precision@5': 0.5172815533980583, 'eval_precision@8': 0.38543689320388347, 'eval_precision@10': 0.3269902912621359, 'eval_precision@15': 0.23572815533980584, 'eval_recall@1': 0.3803027976111778, 'eval_recall@5': 0.7863074416357502, 'eval_recall@8': 0.8716882373857335, 'eval_recall@10': 0.899525878793891, 'eval_recall@15': 0.9419542881180593, 'epoch': 19.0}\n","{'eval_loss': 0.4244482219219208, 'eval_threshold': 0.91, 'eval_accuracy': 0.16310679611650486, 'eval_f1_score_micro': 0.688715953307393, 'eval_f1_score_macro': 0.478721142686868, 'eval_f1_score_samples': 0.6904039570530425, 'eval_f1_score_weighted': 0.7034071054928789, 'eval_auc_score_micro': 0.9866596466305058, 'eval_auc_score_macro': 0.9753463343069229, 'eval_auc_score_samples': 0.9879946233336728, 'eval_auc_score_weighted': 0.97780582175168, 'eval_precision@1': 0.9009708737864077, 'eval_precision@5': 0.516116504854369, 'eval_precision@8': 0.38519417475728157, 'eval_precision@10': 0.32796116504854367, 'eval_precision@15': 0.23546925566343044, 'eval_recall@1': 0.38090381471704926, 'eval_recall@5': 0.7861024793919531, 'eval_recall@8': 0.8702211392196062, 'eval_recall@10': 0.9020594671041785, 'eval_recall@15': 0.9413825513327302, 'epoch': 20.0}\n","{'train_runtime': 14621.9334, 'train_samples_per_second': 556.671, 'train_steps_per_second': 1.57, 'train_loss': 0.16675362935880336, 'epoch': 20.0}\n","07/13/2022 08:40:10 - WARNING - __main__ - evaluating on the validation ds...\n","{'eval_loss': 0.41406503319740295, 'eval_threshold': 0.92, 'eval_accuracy': 0.13980582524271845, 'eval_f1_score_micro': 0.6813602015113349, 'eval_f1_score_macro': 0.48800947513608794, 'eval_f1_score_samples': 0.6854377572227659, 'eval_f1_score_weighted': 0.7037437976267207, 'eval_auc_score_micro': 0.986514027772653, 'eval_auc_score_macro': 0.9754632020663921, 'eval_auc_score_samples': 0.9880968141870402, 'eval_auc_score_weighted': 0.9778971062644026, 'eval_precision@1': 0.8990291262135922, 'eval_precision@5': 0.516116504854369, 'eval_precision@8': 0.3837378640776699, 'eval_precision@10': 0.32699029126213586, 'eval_precision@15': 0.2350809061488673, 'eval_recall@1': 0.38143548369532015, 'eval_recall@5': 0.7842693772190451, 'eval_recall@8': 0.8696422224513691, 'eval_recall@10': 0.9006607983511407, 'eval_recall@15': 0.939016239112049, 'epoch': 20.0}\n","07/13/2022 08:43:00 - WARNING - __main__ - Saving...\n"]}],"source":["!python train.py --model_name=microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext \\\n","                 --experiment_name=non-sup \\\n","                 --num_train_epochs=20"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ByYirdeJ9qNv"},"outputs":[],"source":["drive.flush_and_unmount()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZLjWxCkwEw39"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"train.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}