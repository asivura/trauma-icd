{"cells":[{"cell_type":"markdown","metadata":{"id":"HM0cYE32AN_I"},"source":["### Training & Evaluation of TraumaICDBERT\n","This is a demo for training a TraumaICDBERT model to predict injury ICD-10 codes using Google Colab GPUs.\n","\n","- This notebook is intented to run on Google Colab platform. Using this notebook on Colab implies using Google Drive, for which you need to obtain access to the Shared \"TraumaICDBERT\" Google Drive (contact authors for access), which contains the related codebase and ICD-10 code vocabulary, which you would need to train the model\n","\n","- If you would like to run this code locally instead of using Google Colab, that is easy too. Please download this notebook and modify this notebook to read/write a local file system instead of Google Drive.\n","\n","- We have hidden the dataset with patient health records. In order to run the training and evaluation, please swap in your own dataset by following the comments in the code block named \"### SET UP ###\" below\n","\n","- If you have questions, please reach out to the author (yifu.chen@stanford.edu) for technical support"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42002,"status":"ok","timestamp":1689996388664,"user":{"displayName":"Charles C","userId":"07085794940081015663"},"user_tz":420},"id":"zYncQJ1usYeW","outputId":"2c2c6a9e-6488-44b5-fc09-a4bb77f86420"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.7/214.7 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting openai\n","  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n","Installing collected packages: openai\n","Successfully installed openai-0.27.8\n","Collecting accelerate\n","  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.21.0\n"]}],"source":["!pip install datasets -q\n","!pip install transformers -q -U\n","!pip install wandb -q -U\n","!pip install openai\n","!pip install accelerate -U"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2174,"status":"ok","timestamp":1689996390835,"user":{"displayName":"Charles C","userId":"07085794940081015663"},"user_tz":420},"id":"IZ8aTYsksYeX"},"outputs":[],"source":["import os\n","import pandas as pd\n","import os\n","from collections import defaultdict\n","import datasets\n","import sys, importlib\n","import random\n","import shutil\n","import openai\n","import json\n","from tqdm import tqdm\n","\n","from sklearn.metrics.pairwise import cosine_similarity\n","pd.set_option('display.max_colwidth', None)\n","openai.api_key = \"...\" ### PASTE YOUR OPENAI API KEY HERE, FREE CREDIT WILL BE GRANTED FOR NEW ACCOUNTS"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21085,"status":"ok","timestamp":1689996411915,"user":{"displayName":"Charles C","userId":"07085794940081015663"},"user_tz":420},"id":"mfPkOYdfsYeX","outputId":"0db9b060-045a-49c9-8c07-dbf3eb7dddc5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["### SET UP ###\n","\n","\n","import os\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive', force_remount=True)\n","PROJECT_ROOT_DIR = \"TraumaICDBERT\"\n","CODE_HOME = f'/content/gdrive/Shareddrives/{PROJECT_ROOT_DIR}/code'\n","MODEL_HOME = f'/content/gdrive/Shareddrives/{PROJECT_ROOT_DIR}/models'\n","\n","# THE DIRECTORY WHERE YOUR PATIENT DATA IS STORED\n","SECRET_HOME = '/content/gdrive/MyDrive/Academics/Publications/ICD10_Project/'\n","\n","# YOUR OWN PATIENT DATA CSV FILE HERE. Example Format: https://docs.google.com/spreadsheets/d/19PKbWvzFohSQhzaMaz9lvfDuOqMZI8ZJM7aqzZ57Xeg/edit#gid=0\n","RAW_DATA_PATH = os.path.join(SECRET_HOME,\"injury_icd_dataset.csv\")\n","\n","VOCAB_HOME = f'/content/gdrive/Shareddrives/{PROJECT_ROOT_DIR}/icd-codes'\n","TMP_DIR = '/content/tmp'\n","\n","if not os.path.exists(TMP_DIR):\n","    os.mkdir(TMP_DIR)\n","\n","os.chdir(CODE_HOME)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3347,"status":"ok","timestamp":1689996415260,"user":{"displayName":"Charles C","userId":"07085794940081015663"},"user_tz":420},"id":"VI1iAwucsYeY"},"outputs":[],"source":["### READ THE INJURY CODE VOCABULARY ###\n","\n","icd10_concepts = pd.read_csv(os.path.join(VOCAB_HOME, \"injury_codes_ICD10CM.csv\"), low_memory=False)\n","injuries = icd10_concepts[icd10_concepts[\"concept_code\"].apply(lambda x: len(x)<=5 and x.startswith(\"S\"))]\n","injuries.to_csv(os.path.join(VOCAB_HOME, 'injury_ICD10.csv'))\n","injuries_4_char = injuries[injuries.concept_class_id == '4-char nonbill code'].copy()\n","injuries_4_char[\"label_name\"] = injuries_4_char[\"concept_name\"]\n","injuries_4_char[\"label\"] = injuries_4_char[\"concept_code\"]\n","injuries_4_char.to_csv(os.path.join(VOCAB_HOME, 'injury_ICD10_4_char.csv'))"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":6115,"status":"ok","timestamp":1689996421357,"user":{"displayName":"Charles C","userId":"07085794940081015663"},"user_tz":420},"id":"2YT5d6PmsYeY"},"outputs":[],"source":["### READ THE ANNOTATED PATIENT DATA ###\n","\n","raw_data = pd.read_csv(RAW_DATA_PATH, on_bad_lines='skip')\n","case_icd_codes = raw_data[['patient_id', 'icd_code', 'icd_name', 'diagnosis_region', 'ais_code', 'ais_name']].copy()\n","case_icd_codes = case_icd_codes[case_icd_codes.icd_code.notnull()]\n","case_icd_codes[\"icd_code_4_char\"] = case_icd_codes.icd_code.apply(lambda x: str(x)[:5])\n","case_icd_codes[\"icd_name_4_char\"] = case_icd_codes.icd_name.apply(lambda x: str(x)[:5])\n","\n","\n","# Prepare the mapping from the patient id to the free text trauma notes\n","case_icd_codes = case_icd_codes.merge(injuries_4_char.rename(columns={'concept_code': 'icd_code_4_char'}), how='inner')\n","cases = raw_data[(raw_data.tertiary_impression != '') | (raw_data.tertiary_exam != '')][['patient_id', 'tertiary_exam', 'tertiary_imaging_report', 'tertiary_impression']].copy()\n","cases['total_text_len'] = cases.apply(lambda row: len(str(row.tertiary_exam)) + len(str(row.tertiary_imaging_report)) + len(str(row.tertiary_impression)), axis=1)\n","cases = cases.drop_duplicates(subset=[\"patient_id\"], keep='first')\n","cases.to_csv(os.path.join(SECRET_HOME, 'case.csv'))"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":212,"status":"ok","timestamp":1689996421551,"user":{"displayName":"Charles C","userId":"07085794940081015663"},"user_tz":420},"id":"5qzABNj8sYeY"},"outputs":[],"source":["### EXPLORATORY DATA ANALYSIS ###\n","\n","n_cases_by_4_char_code = case_icd_codes.groupby('icd_code_4_char', as_index=False).agg({'patient_id': 'count'}).rename(columns={'patient_id': 'n_cases'})\n","n_cases_by_4_char_code = n_cases_by_4_char_code[n_cases_by_4_char_code.n_cases > 5]\n","n_cases_by_4_char_code.to_csv(os.path.join(SECRET_HOME, 'n_cases_by_4_char_code.csv'))"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":431,"status":"ok","timestamp":1689996421981,"user":{"displayName":"Charles C","userId":"07085794940081015663"},"user_tz":420},"id":"y0WqznEZsYeY"},"outputs":[],"source":["### FILTER & DEFINE GROUND TRUTH LABELS ###\n","ground_truth_labels = n_cases_by_4_char_code.icd_code_4_char.tolist()\n","\n","with open(os.path.join(SECRET_HOME, 'label-with-superficial.txt'), 'w') as f:\n","    f.write('\\n'.join(ground_truth_labels))"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2106,"status":"ok","timestamp":1689996424085,"user":{"displayName":"Charles C","userId":"07085794940081015663"},"user_tz":420},"id":"UdFSXAdYN-kj"},"outputs":[],"source":["### GENERATE GPT-3 EMBEDDINGS FOR LABELS ###\n","\n","embeddings_path = os.path.join(SECRET_HOME, 'icd-name-davinci-001-embeddings.csv')\n","similarities_path = os.path.join(SECRET_HOME, 'icd-name-davinci-001-simularity-scores.csv')\n","\n","if not os.path.exists(embeddings_path):\n","  model_id = 'text-similarity-davinci-001'\n","  res = openai.Embedding.create(input=ground_truth_labels, engine=model_id)\n","  embeddings = []\n","  for d in res['data']:\n","      embeddings.append({\n","          'label': ground_truth_labels[d['index']],\n","          'embedding': d['embedding']\n","      })\n","  embeddings = pd.DataFrame(embeddings)\n","  embeddings.embedding = embeddings.embedding.apply(json.dumps)\n","  embeddings = injuries_4_char.merge(embeddings, on='label')\n","  embeddings.to_csv(embeddings_path, index=False)\n","else:\n","  embeddings = pd.read_csv(embeddings_path)\n","\n","if not os.path.exists(similarities_path):\n","  label_sim = []\n","  for _, row1 in tqdm(embeddings.iterrows()):\n","      for _, row2 in embeddings.iterrows():\n","        if row1.label != row2.label:\n","          label_sim.append({\n","              'label_1': row1.label,\n","              'label_2': row2.label,\n","              'label_name_1': row1.label_name,\n","              'label_name_2': row2.label_name,\n","              'davinci_cosine_similarity': cosine_similarity([eval(row1.embedding)], [eval(row2.embedding)])[0][0]\n","          })\n","  label_sim = pd.DataFrame(label_sim)\n","  min_sim = label_sim.davinci_cosine_similarity.min()\n","  max_sim = label_sim.davinci_cosine_similarity.max()\n","  label_sim['sim'] = label_sim.davinci_cosine_similarity.apply(lambda x: (x-min_sim)/(max_sim-min_sim))\n","  label_sim.to_csv(similarities_path, index=False)\n","else:\n","  label_sim = pd.read_csv(similarities_path)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":235,"status":"ok","timestamp":1689996424318,"user":{"displayName":"Charles C","userId":"07085794940081015663"},"user_tz":420},"id":"95HNHhXV9-Ln"},"outputs":[],"source":["### PREPARE THE ANNOTATED PATIENT DATA ###\n","\n","# Prepare the mapping from the cases to the ground truth codes\n","case_labels = case_icd_codes[case_icd_codes.icd_code_4_char.isin(ground_truth_labels)][['patient_id', 'icd_code_4_char', 'concept_name']]\n","case_labels.rename(columns={'icd_code_4_char': 'label', 'concept_name': 'label_name'}, inplace=True)\n","case_labels.to_csv(os.path.join(SECRET_HOME, 'case-labels-with-superficial.csv'), index=False)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":1171,"status":"ok","timestamp":1689996425487,"user":{"displayName":"Charles C","userId":"07085794940081015663"},"user_tz":420},"id":"MEYbha1EsYeZ"},"outputs":[],"source":["### SPLIT PATIENTS INTO TRAIN, VALIDATION, TEST SETS ###\n","\n","patient_ids = cases.patient_id.sample(frac=1, random_state=42).unique()\n","\n","train_ratio, validation_ratio, test_ratio = 0.7, 0.15, 0.15\n","\n","train = patient_ids[:int(len(patient_ids)*train_ratio)]\n","validation = patient_ids[int(len(patient_ids)*train_ratio):int(len(patient_ids)*(train_ratio+validation_ratio))]\n","test = patient_ids[int(len(patient_ids)*(train_ratio+validation_ratio)):]\n","\n","\n","with open(os.path.join(SECRET_HOME, 'train.txt'), 'w') as f:\n","  f.write('\\n'.join([str(x) for x in train]))\n","\n","with open(os.path.join(SECRET_HOME, 'validation.txt'), 'w') as f:\n","  f.write('\\n'.join([str(x) for x in validation]))\n","\n","with open(os.path.join(SECRET_HOME, 'test.txt'), 'w') as f:\n","  f.write('\\n'.join([str(x) for x in test]))\n","\n","for x in validation:\n","  assert x not in train\n","  assert x not in test\n","\n","for x in train:\n","  assert x not in validation\n","  assert x not in test\n","\n","for x in test:\n","  assert x not in validation\n","  assert x not in train"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1689996425487,"user":{"displayName":"Charles C","userId":"07085794940081015663"},"user_tz":420},"id":"q9Axs8fzsYeZ"},"outputs":[],"source":["### DEFINE TRAINING HYPERPARAMETERS ###\n","\n","valid_labels = \"4-char-with-superficial\"                          #@param [\"4-char\", \"4-char-top50\", \"4-char-top10\", \"5-char\", \"4-and-5-char\", \"4-char-with-superficial\"]\n","experiment_name = \"4-char-with-superficial-20230720\"   #@param {type:\"string\",  allow-input: true} [\"non-sup\", \"non-sup-pretrain\", \"non-sup-tune-after-pretrain\", \"non-sup-4and5-char-train-on-full\", \"non-sup-train-on-full\", \"4-char-with-superficial\"]\n","model_name = \"michiyasunaga/BioLinkBERT-base\"         #@param [\"michiyasunaga/BioLinkBERT-base\", \"michiyasunaga/BioLinkBERT-large\", \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\"]\n","metric_for_best_model = \"eval_f1_score_weighted\"          #@param [\"eval_f1_score_macro\", \"eval_f1_score_micro\", \"eval_f1_score_weighted\", \"eval_auc_score_macro\", \"eval_auc_score_micro\", \"eval_auc_score_weighted\"]\n","num_epochs = \"6\"                 #@param [3, 6, 10, 20, 30]\n","train_on_full = False            #@param {type:\"boolean\", desc: \"Whether to train on both train and val dataset, and do final eval on holdout test set\"}\n","evaluate_only = True           #@param {type:\"boolean\"}\n","learning_rate = \"0.00002\"        #@param [2e-5, 1e-5, 7e-6, 2e-6]\n","warmup_steps =  5000            #@param [1000, 2000, 3000, 5000]\n","per_device_train_batch_size = \"16\" #@param [512, 256, 128, 64, 32, 24, 16, 8, 6, 4]\n","per_device_eval_batch_size = \"32\" #@param [512, 256, 128, 64, 48, 32, 16, 12, 8]\n","learning_rate = float(learning_rate)\n","warmup_steps = int(warmup_steps)\n","per_device_train_batch_size = int(per_device_train_batch_size)\n","per_device_eval_batch_size = int(per_device_eval_batch_size)"]},{"cell_type":"markdown","source":["Main function to train TraumaICDBERT\n","\n","\n","```\n","--model_name: Name of the Huggingface model to be trained.\n","--data_dir: A directory where the data is stored (referred to as $SECRET_HOME).\n","--model_dir: A directory where the training model will be stored ($MODEL_HOME).\n","--experiment_name: A unique name to identify each experimental run.\n","--valid_labels: The valid ICD-10 labels, such as \"4-char\" or \"4-char-top50\".\n","--is_evaluate: A boolean that when set to true only evaluates the model and does not train it.\n","--train_on_full: A boolean that when set to true, the model will train on the full dataset, and evaluate on the test set.\n","--num_train_epochs: The total number of training epochs to perform.\n","--metric_for_best_model: The metric used to determine the best model.\n","--learning_rate: Learning rate for the model.\n","--warmup_steps: Number of warmup steps for the training model.\n","--per_device_train_batch_size: Batch size per device for training.\n","--per_device_eval_batch_size: Batch size per device for evaluation.\n","Note: To evaluate the trained model, once the training completes, set $evaluate_only to True and re-run the notebook. This will only conduct evaluation and not perform any training. The performance of the model can then be analyzed.\n","```\n","\n"],"metadata":{"id":"zKPyF-EfyfNo"}},{"cell_type":"code","execution_count":13,"metadata":{"id":"RKWH8AQcsYeb","executionInfo":{"status":"ok","timestamp":1689996425487,"user_tz":420,"elapsed":1,"user":{"displayName":"Charles C","userId":"07085794940081015663"}}},"outputs":[],"source":["!python train.py --model_name=$model_name \\\n","                 --data_dir=$SECRET_HOME \\\n","                 --model_dir=$MODEL_HOME \\\n","                 --experiment_name=$experiment_name \\\n","                 --valid_labels=$valid_labels \\\n","                 --is_evaluate=$evaluate_only \\\n","                 --train_on_full=$train_on_full \\\n","                 --num_train_epochs=$num_epochs \\\n","                 --metric_for_best_model=$metric_for_best_model \\\n","                 --learning_rate=$learning_rate \\\n","                 --warmup_steps=$warmup_steps \\\n","                 --per_device_train_batch_size=$per_device_train_batch_size \\\n","                 --per_device_eval_batch_size=$per_device_eval_batch_size\n","\n","# TO EVALUATE THE TRAINED MODEL:\n","# ONCE TRAINING IS FINISHED, SET $evaluate_only TO TRUE AND RE-RUN THIS NOTEBOOK TO EVALUATE THE FINAL MODEL"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"unlZvCX3csvu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689996507396,"user_tz":420,"elapsed":2090,"user":{"displayName":"Charles C","userId":"07085794940081015663"}},"outputId":"b7c295fb-7bf6-49c5-9d7b-fb4eb131865e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluation results for each ICD code have been saved to /content/gdrive/Shareddrives/TraumaICDBERT/models/michiyasunaga/BioLinkBERT-base/4-char-with-superficial-20230720/eval_results.csv\n"]}],"source":["#### EVALUATION CODE ####\n","\n","if evaluate_only:\n","  import pandas as pd\n","  from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n","  import numpy as np\n","  import pickle\n","\n","  path = \"/content/gdrive/Shareddrives/TraumaICDBERT/models/michiyasunaga/BioLinkBERT-base/4-char-with-superficial-20230720/eval_results.pickle\"\n","\n","  with open(path, 'rb') as f:\n","    eval_results = pickle.load(f)\n","\n","  label_to_name = {}\n","\n","  for label in ground_truth_labels:\n","    # find the concept name from injuries_4_char\n","    concept_name = injuries_4_char[injuries_4_char.label == label].concept_name\n","    label_to_name[label] = concept_name.values[0]\n","\n","  def calculate_metrics(y_true, y_pred, y_prob):\n","      if len(np.unique(y_true)) == 1:\n","          metrics = {\n","              \"accuracy\": np.nan,\n","              \"AUC\": np.nan,  # or 0.0 if you prefer\n","              \"precision\": np.nan,  # or 0.0 if you prefer\n","              \"recall\": np.nan,  # or 0.0 if you prefer\n","              \"f1\": np.nan  # or 0.0 if you prefer\n","          }\n","      else:\n","          metrics = {\n","              \"accuracy\": accuracy_score(y_true, y_pred),\n","              \"AUC\": roc_auc_score(y_true, y_prob),\n","              \"precision\": precision_score(y_true, y_pred, zero_division=0),\n","              \"recall\": recall_score(y_true, y_pred, zero_division=0),\n","              \"f1\": f1_score(y_true, y_pred, zero_division=0)\n","          }\n","      return metrics\n","\n","  def create_label_indices_mapping(label_to_name):\n","      label_to_index = {label: idx for idx, label in enumerate(label_to_name.keys())}\n","      return label_to_index\n","\n","  def evaluate_classifier(eval_results, label_to_name):\n","      metrics_df = pd.DataFrame(columns=[\"label\", \"concept_name\", \"accuracy\", \"AUC\", \"precision\", \"recall\", \"F1\"])\n","      y_prob = eval_results[\"probs\"]\n","      y_true = eval_results[\"targets\"]\n","      label_to_index = create_label_indices_mapping(label_to_name)\n","\n","      num_labels = y_true.shape[1]\n","      for label, concept_name in label_to_name.items():\n","          label_index = label_to_index.get(label, -1)\n","          if label_index >= 0 and label_index < num_labels:\n","              y_true_label = y_true[:, label_index]\n","              y_prob_label = y_prob[:, label_index]\n","              y_pred_label = np.round(y_prob_label)\n","              metrics = calculate_metrics(y_true_label, y_pred_label, y_prob_label)\n","              metrics[\"label\"] = label\n","              metrics[\"concept_name\"] = concept_name\n","              metrics_df = pd.concat(\n","              [\n","                  metrics_df,\n","                  pd.DataFrame(metrics, index=[0])\n","              ]\n","          )\n","          else:\n","              print(f\"Label {label} ({concept_name}) not found in eval_results.\")\n","\n","      return metrics_df, y_true_label, y_pred_label, y_prob_label\n","\n","  metrics_df, y_true_label, y_pred_label, y_prob_label = evaluate_classifier(eval_results, label_to_name)\n","\n","  eval_metrics_path = os.path.join(MODEL_HOME, model_name, experiment_name, \"eval_results.csv\")\n","  metrics_df.to_csv(eval_metrics_path, index=False)\n","  print(f\"Evaluation results for each ICD code have been saved to {eval_metrics_path}\")\n","  print(eval_results['metrics'])\n","  display(metrics_df)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}