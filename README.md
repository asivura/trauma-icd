# TraumaICDBERT: A Natural Language Processing Algorithm to Automate Injury ICD-10 Diagnosis Code Extraction from Free Text 

A BERT-based deep learning NLP algorithm to extract ICD-10 codes from unstructured tertiary survey notes of trauma patients.


<img src="https://github.com/asivura/trauma-icd/blob/main/figures/Trauma%20ICD%20Overview.png" width="500">


# Usage

1. Manually collect training data (ICD10 codes) from each EMR. See example here: [Google sheet](https://docs.google.com/spreadsheets/d/19PKbWvzFohSQhzaMaz9lvfDuOqMZI8ZJM7aqzZ57Xeg/edit?usp=sharing)
2. Obtain a list of ICD-10 candidate codes from the official schema `notebooks/ohdsi-vocab.ipynb`
3. Prepare the input-output pairs dataset using `notebooks/prepare-dataset.ipynb`
4. Generate ICD-10 code semantic similarity scores using `notebooks/gpt3-embeddings.ipynb`
5. Use the following command to train and evaluate model:

```
train.py --model_name=$model_name \
                 --data_dir=$DS_HOME \
                 --model_dir=$MODEL_HOME \
                 --experiment_name=$experiment_name \
                 --valid_labels=$valid_labels \
                 --is_evaluate=$evaluate_only \
                 --train_on_full=$train_on_full \
                 --num_train_epochs=$num_epochs \
                 --metric_for_best_model=$metric_for_best_model \
                 --learning_rate=$learning_rate \
                 --warmup_steps=$warmup_steps \
                 --per_device_train_batch_size=$per_device_train_batch_size \
                 --per_device_eval_batch_size=$per_device_eval_batch_size

arguments:

    --model_name: name of the Huggingface model to be trained
    --data_dir: directory where the data is stored.
    --model_dir: directory where the model will be stored.
    --experiment_name: name of the experiment, can be an arbitrary name to identify results from runs.
    --valid_labels: the valid ICD-10 labels, e.g., 4-char, 4-char-top50
    --is_evaluate: boolean to indicate whether to evaluate the model only and not train
    --train_on_full: boolean to indicate whether to train on full dataset, and eval on test set.
    --num_train_epochs: number of epochs to train the model.
    --metric_for_best_model: metric to be used for determining the best model.
    --learning_rate: learning rate for the model.
    --warmup_steps: number of warmup steps for the model.
    --per_device_train_batch_size: batch size for training.
    --per_device_eval_batch_size: batch size for evaluation.

example argument values:

DS_HOME = 'PROJECT_ROOT_DIR/injury-icd-dataset'
CODE_HOME = 'PROJECT_ROOT_DIR/code'
MODEL_HOME = 'PROJECT_ROOT_DIR/models'
valid_labels = "4-char"
experiment_name = "non-sup-4-char-train-on-full"
model_name = "michiyasunaga/BioLinkBERT-large"
metric_for_best_model = "eval_f1_score_weighted"
num_epochs = 20
train_on_full = True
evaluate_only = False
learning_rate = 2e-5
warmup_steps = 5000
per_device_train_batch_size = 16
per_device_eval_batch_size = 32

```

# File Structure

```
./
    injury-icd-dataset/
        case.csv                        -- input text and patient_id, generated by `notebooks/prepare-dataset.ipynb`
        case-labels.csv                 -- each row contains the patient id and an ICD-10 label, generated by ...
        label-case-count.csv            -- the frequency of each 4-character ICD-10 code, generated by ...
        label-non-superficial-top10.txt -- list of top 10 non-superficial injury ICD-10 codes, generated by ...
        label-non-superficial-top50.txt -- list of top 50 non-superficial injury ICD-10 codes, generated by ...
        label-non-superficial.txt       -- list of all non-superficial injury ICD-10 codes, generated by ...
        train.txt                       -- contains training patient id on each line, generated by ...
        validation.txt                  -- contains validation patient id on each line, generated by ...
        train_and_validation.txt       -- contains training and validation patient id on each line, generated by ...
        test.txt                        -- contains test patient id on each line, generated by ...
        icd-name-davinci-001-simularity-scores.csv -- similarity scores between ICD-10 codes, generated by `notebooks/gpt3-embeddings`
    
    models/                             -- files under this directory will be automatically generated by train.py
        michiyasunaga/
            BioLinkBERT-base/
                encoded_ds/             -- encoded dataset, auto-generated using the corresponding HF tokenizer
                    train/
                        ...                 
                    test/
                        ...                 
                    reduced_validation/
                        ...                 
                    validation/
                        ...                 
                    dataset_dict.json
                EXPERIMENT_NAME_1/          -- automatically created by the script
                    checkpoint-12345/
                        config.json
                        pytorch_model.bin
                        trainer_state.json
                        ...
                    checkpoint-67890/
                        ...
                EXPERIMENT_NAME_2/          
                    ...
        ...                              -- other BERT models on HuggingFace can be used as well, e.g., PubMedBERT
    
    notebooks/
        evaluate-awscm.ipynb             -- evaluates AWSCM predictions, requires using AWSCM to process EMRs first
        prepare-awscm-for-evaluation.ipynb.ipynb -- uses AWSCM to process EMRs, requires AWSCM predictions
        gpt3-embeddings.ipynb            -- generates GPT3 embeddings for the dataset, to reduce validation time
        ohdsi-vocab.ipynb                -- generates a list of candidate ICD-10 codes for the dataset
        prepare-dataset.ipynb            -- generates the dataset using patient EMRs and ICD-10 codes for training
        train-colab.ipynb                -- runs the training script on Google Colab cloud GPU

    code/
        dataset.py      -- generates input-output pairs from dataset of patient EMR with ICD-10 code labels
        train.py        -- the main script to train, evaluate, and save the model
        evaluate.py     -- evaluation scripts for obtaining AUC, F1, precision@k, and recall@k scores
        model.py        -- for loading and saving the model checkpoint
    
```

# Training Details

The training task is formatted as follows: the input consists of one ICD-10 code definition (e.g., Multiple fractures of ribs) the tertiary EMR (imaging report + tertiary impression), the output is a binary label of 1 (positive ground truth example) or 0 (negative example). During training, the model is trained on all the positive examples, as well as an equal number of negative examples. Since there are more negative examples than positive examples (a patient may have 4 injuries while there are 170 candidate codes), we randomly sample a subset of the negative examples at each epoch. During reduced_validation, the model is evaluated on all the positive examples and a subset of the negative examples (to improve computational efficiency, we select only the most challenging codes that have similar GPT-3 embeddings with the positive code). When the model is finished training (e.g., for 20 epochs), the model is evaluated in a final loop of all positive examples and all negative examples. For example, each EMR will be inferenced 170 times, where each inference corresponds to a candidate ICD-10 code. The model evaluation metrics is computed using this probability matrix.



# Support
If you have any questions regarding this repository, please open a support ticket on Github, or write to yifuchen [a] stanford [.] edu for guidance.
